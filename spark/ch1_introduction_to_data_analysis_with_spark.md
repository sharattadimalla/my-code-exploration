
* Apache Spark is fast and general purpose cluster computing platform
* Apache Spark extends the mapReduce model to extend to interactive queries and stream processing
* Apache Spark covers workload patterns such as batch, iterative algorithms, interactive queries and streaming
* Apache Spark APIs are available in Python, Java, Scala, R and SQL with rich built-in libraries

* Spark is a computational engine that is responsible for scheduling, distributing and monitoring applications consisting of many
computational tasks across many worker machines or computational cluster

* Spark Stack consists of 
	* Spark Core
	* Schedulers - Standalone Schduler, YARN or MESOS
	* Spark SQL
	* Spark Streaming
	* MLib
	* GraphX

* RDD - Resilient Distributed Dataset is the fundamental programming abstraction in Spark.
* RDD is a collection of items distributed across many compute nodes that can be manipulated in Spark

* Spark SQL is a package for working with structured data.

* Spark streaming enables processing of live streams of data. Ex:- logfiles, queue of messages

* MLib contains machine learning algorithms like classification, regression, clustering and collaborative filtering.

* GraphX is a library to manipulate graphs.

* Spark is used by data scientists and data engineers.

* Spark is used for data science and data applications.

* Spark started in 2009 as a research project in the UC Berkeley RAD Lab later to become AMPLab.

* MapReduce was inefficient for interative and interactive computing jobs.

